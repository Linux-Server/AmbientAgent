{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89ab5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location:str)->str:\n",
    "    \"\"\"Get the weather of current location\"\"\"\n",
    "    return f\"The weather in {location} is windy\"\n",
    "\n",
    "agent= create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[get_weather],\n",
    "    # checkpointer=InMemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b703502f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in kochi?', additional_kwargs={}, response_metadata={}, id='42221b06-9b9a-43c1-b4ce-ab4a6673ee69'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 217, 'prompt_tokens': 133, 'total_tokens': 350, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D3JF9MQ9THm44DRcuTgk9GNlQ4a7c', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c093a-144c-7623-98a1-46c7e490fa7e-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Kochi'}, 'id': 'call_pkXSWO7uSzNawReK6MXCocKy', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 133, 'output_tokens': 217, 'total_tokens': 350, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}),\n",
       "  ToolMessage(content='The weather in Kochi is windy', name='get_weather', id='11594185-c563-4f74-8e6a-874c558d6954', tool_call_id='call_pkXSWO7uSzNawReK6MXCocKy'),\n",
       "  AIMessage(content='The weather in Kochi is windy.\\n\\nWould you like a temperature, humidity, and short forecast for the next few hours or days?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 420, 'prompt_tokens': 170, 'total_tokens': 590, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D3JFCytdDWGVuxNJJa23qDWf019Pw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c093a-1ef3-7113-8739-2ab5fd9ab8c3-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 170, 'output_tokens': 420, 'total_tokens': 590, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = agent.invoke({\"messages\": [{\"role\" :\"user\", \"content\":\"What is the weather in kochi?\"}]})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82e5ba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather in kochi?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_pkXSWO7uSzNawReK6MXCocKy)\n",
      " Call ID: call_pkXSWO7uSzNawReK6MXCocKy\n",
      "  Args:\n",
      "    location: Kochi\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "The weather in Kochi is windy\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The weather in Kochi is windy.\n",
      "\n",
      "Would you like a temperature, humidity, and short forecast for the next few hours or days?\n"
     ]
    }
   ],
   "source": [
    "for m in res[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0363c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      7\u001b[39m agent= create_agent(\n\u001b[32m      8\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-5-nano\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     checkpointer=checkpointer\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m state = agent.get_state({\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m99\u001b[39m\u001b[33m\"\u001b[39m}})\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg.type.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver  \n",
    "from langchain.agents import create_agent\n",
    "DB_URI = \"postgresql://myuser:mypassword@localhost:5432/mydb\"\n",
    "\n",
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    checkpointer.setup()\n",
    "    agent= create_agent(\n",
    "        model=\"gpt-5-nano\",\n",
    "        checkpointer=checkpointer\n",
    "    )\n",
    "\n",
    "    state = agent.get_state({\"configurable\": {\"thread_id\": \"99\"}})\n",
    "\n",
    "    for msg in state[\"messages\"]:\n",
    "        print(f\"{msg.type.upper()}: {msg.content}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d8e5dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in kochi?', additional_kwargs={}, response_metadata={}, id='75c50cbb-dd28-444b-8b33-55b1935dc2ce'),\n",
       "  AIMessage(content='Do you mean Kochi, Kerala, India (the well-known city), or Kochi in Japan? If you mean Kochi, Kerala, I can give you:\\n\\n- Current weather (live conditions) — I can check a live forecast if you want me to fetch it.\\n- Or a quick climate overview and typical conditions.\\n\\nIf you’d like a general climate snapshot right now:\\n- Climate: tropical monsoon, hot and very humid most of the year.\\n- Typical temps: highs around 32–34°C (90–93°F); lows around 23–26°C (73–79°F).\\n- Rain: heavy monsoon rains from June–September (southwest monsoon), plus some rain in Oct–Dec (northeast monsoon); drier but still humid Dec–Feb.\\n- Best time to visit: November–February when the weather is cooler and rain is less frequent.\\n\\nIf you want current conditions, tell me:\\n- Which Kochi you mean (Kerala or Japan)?\\n- Your preferred units (Celsius or Fahrenheit).\\n- Do you want me to fetch the latest current weather for you?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2093, 'prompt_tokens': 14, 'total_tokens': 2107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1856, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D3KRRPJKfZBon5YPDKRg395lNwL9j', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c0980-5949-7f40-b012-b178b61ed582-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 2093, 'total_tokens': 2107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1856}})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec6e99ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "the connection is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m state = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m99\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg.type.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Langchain-agent/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:1266\u001b[39m, in \u001b[36mPregel.get_state\u001b[39m\u001b[34m(self, config, subgraphs)\u001b[39m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(thread_id, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1264\u001b[39m     config[CONF][CONFIG_KEY_THREAD_ID] = \u001b[38;5;28mstr\u001b[39m(thread_id)\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m saved = \u001b[43mcheckpointer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_state_snapshot(\n\u001b[32m   1268\u001b[39m     config,\n\u001b[32m   1269\u001b[39m     saved,\n\u001b[32m   1270\u001b[39m     recurse=checkpointer \u001b[38;5;28;01mif\u001b[39;00m subgraphs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1271\u001b[39m     apply_pending_writes=CONFIG_KEY_CHECKPOINT_ID \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config[CONF],\n\u001b[32m   1272\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Langchain-agent/.venv/lib/python3.13/site-packages/langgraph/checkpoint/postgres/__init__.py:229\u001b[39m, in \u001b[36mPostgresSaver.get_tuple\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    226\u001b[39m     args = (thread_id, checkpoint_ns)\n\u001b[32m    227\u001b[39m     where = \u001b[33m\"\u001b[39m\u001b[33mWHERE thread_id = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m AND checkpoint_ns = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m ORDER BY checkpoint_id DESC LIMIT 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcur\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mSELECT_SQL\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetchone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/contextlib.py:141\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Langchain-agent/.venv/lib/python3.13/site-packages/langgraph/checkpoint/postgres/__init__.py:430\u001b[39m, in \u001b[36mPostgresSaver._cursor\u001b[39m\u001b[34m(self, pipeline)\u001b[39m\n\u001b[32m    428\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m cur\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdict_row\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[32m    431\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m cur\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Langchain-agent/.venv/lib/python3.13/site-packages/psycopg/connection.py:239\u001b[39m, in \u001b[36mConnection.cursor\u001b[39m\u001b[34m(self, name, binary, row_factory, scrollable, withhold)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcursor\u001b[39m(\n\u001b[32m    228\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    229\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    234\u001b[39m     withhold: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    235\u001b[39m ) -> Cursor[Any] | ServerCursor[Any]:\n\u001b[32m    236\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[33;03m    Return a new `Cursor` to send commands and queries to the connection.\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_connection_ok\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m row_factory:\n\u001b[32m    242\u001b[39m         row_factory = \u001b[38;5;28mself\u001b[39m.row_factory\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Langchain-agent/.venv/lib/python3.13/site-packages/psycopg/_connection_base.py:532\u001b[39m, in \u001b[36mBaseConnection._check_connection_ok\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pgconn.status == BAD:\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.OperationalError(\u001b[33m\"\u001b[39m\u001b[33mthe connection is closed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e.InterfaceError(\n\u001b[32m    534\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcannot execute operations: the connection is\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    535\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m in status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.pgconn.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    536\u001b[39m )\n",
      "\u001b[31mOperationalError\u001b[39m: the connection is closed"
     ]
    }
   ],
   "source": [
    "state = agent.get_state({\"configurable\": {\"thread_id\": \"99\"}})\n",
    "\n",
    "for msg in state[\"messages\"]:\n",
    "    print(f\"{msg.type.upper()}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a74d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-agent (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
